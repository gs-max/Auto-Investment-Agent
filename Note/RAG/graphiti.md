# 对于一些注释较少的基本类型和变量的理解

## episodic
记录处理的内容，在问答机器人中就是用户和llm的对话。连接很多实体，entity和自定义的这些。都是llm从内容中提取出来的。

## community
这叫CommunityNode，我目前感觉像是对相关内容的总结，周围有不同的实体。和上面不一样的是，这些community会不断变化
，一个group_id中所有相关的实体都会聚集在一起，而不是安每段处理的内容来分类。比如，我问了苹果公司和谷歌在业务上的区别，
又问了Virson Pro，这两次对话的内容被总结成一个CommunityNode。两次对话中的实体都和这个CommunityNode有联系。

## group_id
目前来看用来做用户的隔离确实是不二之选。add_episode的时候加入group_id，之后在search的时候也用这个group_id就可以
实现不同用户之间的数据隔离。

## uuid
这个我目前不清楚有什么比较重要的作用，目前就知道在CRUD的时候有用，不过我还没用到。目前的想法就是封装成工具给大模型，
可以根据知识的更新对图中的点或边做修改。但是怎么获取一个节点的uuid呢？可能还得查数据库得到。那uuid和id又有什么区别呢？

## 关于搜索
有三种：
1. 可以根据uuid搜索特定的实体，并重点考虑和目标实体相近的结果
2. 最普通的搜索，直接穿入query
3. 自定义配置搜索（到这里感觉就偏向RAG那套东西了，自定义搜索方法。得到结果后之后还要重排列）

## 插入三元组
加入起点（EntityNode）和终点（EntityNode）以及边（EntityEdge）。

# 我的理解
我目前的理解就是把一段内容传递给graphiti.client，在这之后使用llm去提取entity和edge。有自定义的实体类型就用自定义的，
没有的话就用默认的Entity。边的话有自定义的边就用自定义的，没有的话好像会智能生成。但是从目前的实验看来自定义的边有的
数据没有被提取成功，不是没有值，是根本就没有那个属性。在提取完之后，一般就会生成Entity,SelfEntity,Episodic,CommunityNode
这些节点以及Mention,Relates_to以及Has_Members这些边。Mentions通常表Episode和Entity之间的关系，没什么重要的属性。
Has_Member常见于CommunityNode与EntityNode之间，比较有用的感觉就是summary属性。最后是Relates_To，常见于实体和实体
之间，这部分就是我们自定义的或是智能生成的关系。在这中关系中，除了自定义的关系(边)设置的属性。还有比较重要的属性是fact和episode.
前者我感觉更像是对epsiode的content的总结，后者是episode(对话)的uuid。

# 踩的一些坑
用一般的大模型去做实体提取会出现类型不正确的错误。说是不符合neo4j的要求，一开始以为是数据库的问题，浪费了一天。后来转变思路应该是
LLM提取后格式不对的问题。针对这种情况，我首先想到的是利用peompt做输出格式的调整，修改了openai_generic_clien对模型输出提出的prompt，
简单来讲就是加了few_shot，但是不管用，遂采用了另一种方法，我发现每次报错一般都是那几种，索性直接检查是那种错误，根据错误设计prompt
告诉LLM遇到这种情况该怎么写。效果不错，目前能正常运行，未来再有错误就继续加prompt。但是这种方法还是不够优雅，我应该改进第一种方法，
试试更好的prompt。

另外，现在我觉得从LLM问答给出结果到保存到数据库完成用的时间有点长，这需要改进。还有qwen的向量化模型每次只能处理25条数据，但是提取出的
实体和关系又时候可不会那么少，这也得想想办法。Community也是一个问题，应该在在每轮对话后时时变化，但是这个操作所需时长又不短。另外，
代码里的提示词太粗糙了，目前看来还是遇到问题再优化的策略比较好。

至于更深的理解明天再说吧。